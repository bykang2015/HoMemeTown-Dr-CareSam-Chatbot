"""
ë°•ì‚¬í•™ìœ„ë…¼ë¬¸ ì‹¤í—˜ 3: ì •ì‹ ê±´ê°• ì±—ë´‡ ìƒë‹´í•™ì  í‰ê°€ ê°€ì„¤ê²€ì¦
Dr.CareSam vs Global Mental Health Chatbots Comparative Analysis

ì´ ì½”ë“œëŠ” JMIR MI ë…¼ë¬¸ê³¼ëŠ” ë³„ê°œë¡œ, ë°•ì‚¬í•™ìœ„ë…¼ë¬¸ì˜ ì‹¤í—˜ 3ì—ì„œ 
4ê°œì˜ ê°€ì„¤ì„ ê²€ì¦í•˜ê¸° ìœ„í•œ í†µê³„ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

Author: [Boyoung Kang]
Institution: [Sungkyunkwan University]
Date: 2025
ì—…ë°ì´íŠ¸: ICC ë¶„ì„ â†’ í”¼ì–´ìŠ¨ ìƒê´€ë¶„ì„ìœ¼ë¡œ ë³€ê²½
"""

import numpy as np
import pandas as pd
import scipy.stats as stats
from scipy.stats import f_oneway, pearsonr
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.stats.multicomp import pairwise_tukeyhsd
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì • (ì„ íƒì‚¬í•­)
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['figure.figsize'] = (12, 8)

class PhDThesisExperiment3Analysis:
    """
    ë°•ì‚¬ë…¼ë¬¸ ì‹¤í—˜ 3: ì •ì‹ ê±´ê°• ì±—ë´‡ ìƒë‹´í•™ì  í‰ê°€ ê°€ì„¤ê²€ì¦
    
    ê°€ì„¤:
    Hâ‚: 7ê°€ì§€ ìƒë‹´í•™ì  í‰ê°€ ê¸°ì¤€ì˜ ë³€ë³„ë ¥
    Hâ‚‚: ë‹¥í„°ì¼€ì–´ìŒ¤ì˜ ê¸€ë¡œë²Œ ìˆ˜ì¤€ ì„±ëŠ¥
    Hâ‚ƒ: LLM-ì¸ê°„ í‰ê°€ì ê°„ ì¼ì¹˜ë„ (í”¼ì–´ìŠ¨ ìƒê´€ë¶„ì„)
    Hâ‚„: NLP vs ìƒë‹´í•™ì  í‰ê°€ì˜ ì°¨ì´
    """
    
    def __init__(self):
        """ì‹¤ì œ ë°•ì‚¬ë…¼ë¬¸ í‰ê°€ ë°ì´í„° ì´ˆê¸°í™”"""
        
        # ì‹¤ì œ í‰ê°€ ë°ì´í„° (7ê°œ ê¸°ì¤€ Ã— 3ëª… í‰ê°€ì Ã— 4ê°œ ì±—ë´‡)
        self.evaluation_data = {
            'ê³µê°ì„±': {
                'Claude': {'Replika': 3, 'Wysa': 2, 'Youper': 2, 'Dr.CareSam': 3},
                'ChatGPT': {'Replika': 2, 'Wysa': 3, 'Youper': 2, 'Dr.CareSam': 3},
                'Human': {'Replika': 3, 'Wysa': 2, 'Youper': 3, 'Dr.CareSam': 3}
            },
            'ì •í™•ì„±ê³¼_ìœ ìµì„±': {
                'Claude': {'Replika': 2, 'Wysa': 3, 'Youper': 2, 'Dr.CareSam': 2},
                'ChatGPT': {'Replika': 2, 'Wysa': 3, 'Youper': 2, 'Dr.CareSam': 2},
                'Human': {'Replika': 2, 'Wysa': 3, 'Youper': 3, 'Dr.CareSam': 2}
            },
            'ëª©ì ì _ì‚¬ê³ ì™€_ê°ì •': {
                'Claude': {'Replika': 1, 'Wysa': 3, 'Youper': 1, 'Dr.CareSam': 2},
                'ChatGPT': {'Replika': 1, 'Wysa': 3, 'Youper': 2, 'Dr.CareSam': 2},
                'Human': {'Replika': 2, 'Wysa': 3, 'Youper': 2, 'Dr.CareSam': 2}
            },
            'ì ê·¹ì _ê²½ì²­ê³¼_ì ì ˆí•œ_ì§ˆë¬¸': {
                'Claude': {'Replika': 2, 'Wysa': 3, 'Youper': 2, 'Dr.CareSam': 2},
                'ChatGPT': {'Replika': 1, 'Wysa': 3, 'Youper': 2, 'Dr.CareSam': 2},
                'Human': {'Replika': 2, 'Wysa': 3, 'Youper': 3, 'Dr.CareSam': 2}
            },
            'ê¸ì •ì„±ê³¼_ì§€ì§€': {
                'Claude': {'Replika': 2, 'Wysa': 2, 'Youper': 3, 'Dr.CareSam': 3},
                'ChatGPT': {'Replika': 2, 'Wysa': 2, 'Youper': 3, 'Dr.CareSam': 3},
                'Human': {'Replika': 2, 'Wysa': 2, 'Youper': 3, 'Dr.CareSam': 3}
            },
            'ì „ë¬¸ì„±': {
                'Claude': {'Replika': 2, 'Wysa': 3, 'Youper': 2, 'Dr.CareSam': 2},
                'ChatGPT': {'Replika': 1, 'Wysa': 3, 'Youper': 2, 'Dr.CareSam': 2},
                'Human': {'Replika': 2, 'Wysa': 3, 'Youper': 3, 'Dr.CareSam': 2}
            },
            'ê°œì¸í™”': {
                'Claude': {'Replika': 1, 'Wysa': 2, 'Youper': 1, 'Dr.CareSam': 3},
                'ChatGPT': {'Replika': 1, 'Wysa': 3, 'Youper': 2, 'Dr.CareSam': 3},
                'Human': {'Replika': 2, 'Wysa': 3, 'Youper': 2, 'Dr.CareSam': 2}
            }
        }
        
        # NLP ì§€í‘œ ë°ì´í„° (ê¸°ì¡´ ë…¼ë¬¸ì—ì„œ ê³„ì‚°ëœ ê°’)
        self.nlp_metrics = {
            'Youper': {'bleu': 0.144, 'rouge': 0.254, 'meteor': 0.31, 'bertscore': 0.288},
            'Wysa': {'bleu': 0.141, 'rouge': 0.25, 'meteor': 0.29, 'bertscore': 0.27},
            'Replika': {'bleu': 0.0, 'rouge': 0.15, 'meteor': 0.227, 'bertscore': 0.28},
            'Dr.CareSam': {'bleu': 0.04, 'rouge': 0.129, 'meteor': 0.159, 'bertscore': 0.184}
        }
        
        # ê¸°ë³¸ ì„¤ì •
        self.chatbots = ['Replika', 'Wysa', 'Youper', 'Dr.CareSam']
        self.criteria = list(self.evaluation_data.keys())
        self.evaluators = ['Claude', 'ChatGPT', 'Human']
        
        # ë°ì´í„° ì „ì²˜ë¦¬
        self._prepare_data()
        
    def _prepare_data(self):
        """ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ì „ì²˜ë¦¬"""
        
        # 1. ëª¨ë“  ê°œë³„ ì ìˆ˜ ì¶”ì¶œ
        self.individual_scores = {chatbot: [] for chatbot in self.chatbots}
        self.chatbot_totals = {}
        self.chatbot_means = {}
        
        for chatbot in self.chatbots:
            total = 0
            for criterion in self.criteria:
                for evaluator in self.evaluators:
                    score = self.evaluation_data[criterion][evaluator][chatbot]
                    self.individual_scores[chatbot].append(score)
                    total += score
            
            self.chatbot_totals[chatbot] = total
            self.chatbot_means[chatbot] = total / (len(self.criteria) * len(self.evaluators))
        
        # 2. í‰ê°€ìë³„ ì´ì  ê³„ì‚°
        self.evaluator_totals = {}
        for evaluator in self.evaluators:
            self.evaluator_totals[evaluator] = []
            for chatbot in self.chatbots:
                chatbot_total = sum(
                    self.evaluation_data[criterion][evaluator][chatbot] 
                    for criterion in self.criteria
                )
                self.evaluator_totals[evaluator].append(chatbot_total)
        
        print("ğŸ“Š ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ")
        print(f"êµ¬ì¡°: {len(self.criteria)}ê°œ ê¸°ì¤€ Ã— {len(self.evaluators)}ëª… í‰ê°€ì Ã— {len(self.chatbots)}ê°œ ì±—ë´‡")
        print("ì±—ë´‡ë³„ ì´ì :")
        for chatbot in self.chatbots:
            print(f"  {chatbot}: {self.chatbot_totals[chatbot]}ì  (í‰ê·  {self.chatbot_means[chatbot]:.3f})")
    
    def hypothesis_1_discrimination_analysis(self):
        """
        ê°€ì„¤ 1 ê²€ì¦: 7ê°€ì§€ ìƒë‹´í•™ì  í‰ê°€ ê¸°ì¤€ì˜ ë³€ë³„ë ¥
        Hâ‚: ì‹¤í—˜ IIì—ì„œ ë„ì¶œëœ 7ê°€ì§€ ìƒë‹´í•™ì  í‰ê°€ ê¸°ì¤€ì€ LLM ê¸°ë°˜ í‰ê°€ ë°©ë²•ë¡ ì„ í†µí•´ 
            ì„œë¡œ ë‹¤ë¥¸ íŠ¹ì„±ì„ ê°€ì§„ ì •ì‹ ê±´ê°• ì±—ë´‡ë“¤ ê°„ì˜ ìƒë‹´ì  í’ˆì§ˆ ì°¨ì´ë¥¼ ìœ ì˜ë¯¸í•˜ê²Œ ë³€ë³„í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.
        """
        print("\n" + "="*80)
        print("ê°€ì„¤ 1 ê²€ì¦: 7ê°€ì§€ ìƒë‹´í•™ì  í‰ê°€ ê¸°ì¤€ì˜ ë³€ë³„ë ¥")
        print("="*80)
        
        # One-way ANOVA ìˆ˜í–‰
        group_scores = [self.individual_scores[chatbot] for chatbot in self.chatbots]
        f_stat, p_value = f_oneway(*group_scores)
        
        # íš¨ê³¼í¬ê¸° ê³„ì‚° (eta-squared)
        all_scores = []
        for scores in group_scores:
            all_scores.extend(scores)
        
        grand_mean = np.mean(all_scores)
        n_per_group = len(group_scores[0])  # 21
        k = len(group_scores)  # 4
        
        # SSB (Between-group sum of squares)
        group_means = [np.mean(scores) for scores in group_scores]
        ssb = n_per_group * sum((mean - grand_mean)**2 for mean in group_means)
        
        # SSW (Within-group sum of squares)
        ssw = sum(sum((score - group_mean)**2 for score in group_scores[i]) 
                 for i, group_mean in enumerate(group_means))
        
        eta_squared = ssb / (ssb + ssw)
        
        # ê²°ê³¼ ì¶œë ¥
        df_between = k - 1
        df_within = len(all_scores) - k
        
        print(f"ì¼ì›ë°°ì¹˜ ë¶„ì‚°ë¶„ì„ ê²°ê³¼:")
        print(f"F({df_between}, {df_within}) = {f_stat:.2f}")
        print(f"p-value = {p_value:.6f} {'(p < 0.001)' if p_value < 0.001 else ''}")
        print(f"Î·Â² = {eta_squared:.3f} ({'í°' if eta_squared > 0.14 else 'ì¤‘ê°„' if eta_squared > 0.06 else 'ì‘ì€'} íš¨ê³¼í¬ê¸°)")
        
        # Tukey HSD ì‚¬í›„ê²€ì •
        all_data = []
        all_labels = []
        for chatbot, scores in zip(self.chatbots, group_scores):
            all_data.extend(scores)
            all_labels.extend([chatbot] * len(scores))
        
        df_tukey = pd.DataFrame({'score': all_data, 'chatbot': all_labels})
        tukey_result = pairwise_tukeyhsd(df_tukey['score'], df_tukey['chatbot'], alpha=0.05)
        
        print(f"\nTukey HSD ì‚¬í›„ê²€ì • ê²°ê³¼:")
        print(tukey_result)
        
        # ê°€ì„¤ ê²€ì¦ ê²°ë¡ 
        if p_value < 0.05:
            print(f"\nâœ… ê°€ì„¤ 1 ì±„íƒ")
            print(f"   ìƒë‹´í•™ì  í‰ê°€ ê¸°ì¤€ì´ ì±—ë´‡ ê°„ ìœ ì˜ë¯¸í•œ ì°¨ì´ë¥¼ ë³€ë³„í•¨")
            print(f"   F({df_between},{df_within}) = {f_stat:.2f}, p < 0.001, Î·Â² = {eta_squared:.3f}")
        else:
            print(f"\nâŒ ê°€ì„¤ 1 ê¸°ê°: ìœ ì˜ë¯¸í•œ ì°¨ì´ ì—†ìŒ (p = {p_value:.3f})")
        
        return {
            'f_stat': f_stat,
            'p_value': p_value,
            'eta_squared': eta_squared,
            'tukey_result': tukey_result,
            'hypothesis_accepted': p_value < 0.05
        }
    
    def hypothesis_2_drcare_performance(self):
        """
        ê°€ì„¤ 2 ê²€ì¦: ë‹¥í„°ì¼€ì–´ìŒ¤ì˜ ê¸€ë¡œë²Œ ì±—ë´‡ ëŒ€ë¹„ ì„±ëŠ¥
        Hâ‚‚: ë‹¥í„°ì¼€ì–´ìŒ¤ì€ ê¸€ë¡œë²Œ ìˆ˜ì¤€ì˜ ì •ì‹ ê±´ê°• ì±—ë´‡ë“¤ê³¼ ëŒ€ë“±í•œ ìƒë‹´ì  ì„±ëŠ¥ì„ ë³´ì¼ ê²ƒì´ë‹¤.
        """
        print("\n" + "="*80)
        print("ê°€ì„¤ 2 ê²€ì¦: ë‹¥í„°ì¼€ì–´ìŒ¤ì˜ ê¸€ë¡œë²Œ ìˆ˜ì¤€ ì„±ëŠ¥")
        print("="*80)
        
        # ì„±ëŠ¥ ìˆœìœ„ ê³„ì‚°
        ranked_chatbots = sorted(self.chatbot_means.items(), key=lambda x: x[1], reverse=True)
        
        print("ìƒë‹´í•™ì  í‰ê°€ ì„±ëŠ¥ ìˆœìœ„:")
        for i, (chatbot, mean_score) in enumerate(ranked_chatbots, 1):
            total_score = self.chatbot_totals[chatbot]
            print(f"{i}ìœ„: {chatbot} - ì´ {total_score}ì  (í‰ê·  {mean_score:.3f})")
        
        # ë‹¥í„°ì¼€ì–´ìŒ¤ ìœ„ì¹˜ ë¶„ì„
        drcare_rank = next(i for i, (name, _) in enumerate(ranked_chatbots, 1) if name == 'Dr.CareSam')
        drcare_mean = self.chatbot_means['Dr.CareSam']
        
        print(f"\në‹¥í„°ì¼€ì–´ìŒ¤ ì„±ëŠ¥ ë¶„ì„:")
        print(f"- ì „ì²´ ìˆœìœ„: {drcare_rank}ìœ„/4ê°œ ì±—ë´‡")
        print(f"- í‰ê·  ì ìˆ˜: {drcare_mean:.3f}")
        print(f"- ì´ì : {self.chatbot_totals['Dr.CareSam']}ì ")
        
        # ê°œë³„ t-ê²€ì •ìœ¼ë¡œ ë‹¤ë¥¸ ì±—ë´‡ê³¼ ë¹„êµ
        drcare_scores = self.individual_scores['Dr.CareSam']
        
        print(f"\në‹¤ë¥¸ ì±—ë´‡ê³¼ì˜ ì„±ëŠ¥ ë¹„êµ (ë…ë¦½í‘œë³¸ t-ê²€ì •):")
        comparisons = []
        
        for other_chatbot in self.chatbots:
            if other_chatbot != 'Dr.CareSam':
                other_scores = self.individual_scores[other_chatbot]
                t_stat, p_value = stats.ttest_ind(drcare_scores, other_scores)
                mean_diff = np.mean(drcare_scores) - np.mean(other_scores)
                
                comparisons.append({
                    'chatbot': other_chatbot,
                    't_stat': t_stat,
                    'p_value': p_value,
                    'mean_diff': mean_diff,
                    'significant': p_value < 0.05
                })
                
                significance = "**" if p_value < 0.01 else "*" if p_value < 0.05 else "ns"
                direction = "ìš°ìœ„" if mean_diff > 0 else "ì—´ìœ„"
                print(f"vs {other_chatbot}: t = {t_stat:.3f}, p = {p_value:.3f} {significance} "
                      f"({direction}, ì°¨ì´: {mean_diff:+.3f})")
        
        # ê°€ì„¤ ê²€ì¦ ê²°ë¡ 
        # "ëŒ€ë“±í•œ ì„±ëŠ¥"ì„ ìƒìœ„ 50% (2ìœ„ ì´ë‚´)ë¡œ í•´ì„
        global_level_threshold = 2
        
        print(f"\nê°€ì„¤ ê²€ì¦ ê²°ê³¼:")
        if drcare_rank <= global_level_threshold:
            print(f"âœ… ê°€ì„¤ 2 ì±„íƒ")
            print(f"   ë‹¥í„°ì¼€ì–´ìŒ¤ì´ ê¸€ë¡œë²Œ ìˆ˜ì¤€ì˜ ìƒìœ„ê¶Œ ì„±ëŠ¥ ë‹¬ì„± ({drcare_rank}ìœ„)")
            
            # ìƒìœ„ ì±—ë´‡ê³¼ ìœ ì˜í•œ ì°¨ì´ê°€ ì—†ìœ¼ë©´ ë” ê°•í•œ ê·¼ê±°
            top_chatbot = ranked_chatbots[0][0]
            if top_chatbot != 'Dr.CareSam':
                top_comparison = next(c for c in comparisons if c['chatbot'] == top_chatbot)
                if not top_comparison['significant']:
                    print(f"   ìµœê³  ì„±ëŠ¥ {top_chatbot}ì™€ ìœ ì˜í•œ ì°¨ì´ ì—†ìŒ (p = {top_comparison['p_value']:.3f})")
        else:
            print(f"âŒ ê°€ì„¤ 2 ê¸°ê°")
            print(f"   ê¸€ë¡œë²Œ ìˆ˜ì¤€ì— ë¯¸ë‹¬ ({drcare_rank}ìœ„)")
        
        return {
            'rank': drcare_rank,
            'mean_score': drcare_mean,
            'comparisons': comparisons,
            'ranked_results': ranked_chatbots,
            'hypothesis_accepted': drcare_rank <= global_level_threshold
        }
    
    def hypothesis_3_inter_rater_reliability(self):
        """
        ê°€ì„¤ 3 ê²€ì¦: LLM-ì¸ê°„ í‰ê°€ì ê°„ ì¼ì¹˜ë„ (í”¼ì–´ìŠ¨ ìƒê´€ë¶„ì„)
        Hâ‚ƒ: LLM í‰ê°€ì(Claude 3.5 Sonnet, ChatGPT 4.0)ì™€ ì¸ê°„ ì „ë¬¸ê°€ ê°„ì˜ í‰ê°€ ê²°ê³¼ëŠ” 
            ì¤‘ê°„ ìˆ˜ì¤€ ì´ìƒì˜ ìƒê´€ê´€ê³„ë¥¼ ë³´ì¼ ê²ƒì´ë‹¤.
        """
        print("\n" + "="*80)
        print("ê°€ì„¤ 3 ê²€ì¦: LLM-ì¸ê°„ í‰ê°€ì ê°„ ì¼ì¹˜ë„ (í”¼ì–´ìŠ¨ ìƒê´€ë¶„ì„)")
        print("="*80)
        
        # í‰ê°€ìë³„ ê¸°ìˆ í†µê³„
        print(f"í‰ê°€ìë³„ ê¸°ìˆ í†µê³„:")
        print("â”€" * 40)
        for evaluator in self.evaluators:
            evaluator_scores = self.evaluator_totals[evaluator]
            mean_score = np.mean(evaluator_scores)
            std_score = np.std(evaluator_scores, ddof=1)
            print(f"{evaluator}: M = {mean_score:.3f}, SD = {std_score:.3f}")
        
        # ê°œë³„ í‰ê°€ì ê°„ ìƒê´€ê´€ê³„ ë¶„ì„
        print(f"\nê°œë³„ í‰ê°€ì ê°„ ìƒê´€ê´€ê³„:")
        print("â”€" * 50)
        evaluator_pairs = [
            ('Claude', 'ChatGPT'),
            ('Claude', 'Human'), 
            ('ChatGPT', 'Human')
        ]
        
        correlations = {}
        threshold = 0.5  # ì¤‘ê°„ ìˆ˜ì¤€ ìƒê´€ê´€ê³„ ê¸°ì¤€
        llm_human_above_threshold = 0
        significant_correlations = 0
        
        for eval1, eval2 in evaluator_pairs:
            correlation, p_value = pearsonr(
                self.evaluator_totals[eval1], 
                self.evaluator_totals[eval2]
            )
            correlations[f"{eval1}_vs_{eval2}"] = {
                'correlation': correlation,
                'p_value': p_value,
                'significant': p_value < 0.05
            }
            
            if p_value < 0.05:
                significant_correlations += 1
            
            significance = "**" if p_value < 0.01 else "*" if p_value < 0.05 else "ns"
            interpretation = "ê°•í•œ" if correlation > 0.7 else "ì¤‘ê°„-ê°•í•œ" if correlation > 0.5 else "ì¤‘ê°„" if correlation > 0.3 else "ì•½í•œ"
            status = "âœ“" if correlation > threshold else "âœ—"
            
            print(f"{eval1} vs {eval2}: r = {correlation:.3f}, p = {p_value:.3f} {significance} "
                  f"{status} ({interpretation})")
            
            # LLM-ì¸ê°„ ìƒê´€ê´€ê³„ë§Œ ì¹´ìš´íŠ¸
            if 'Human' in [eval1, eval2]:
                if correlation > threshold:
                    llm_human_above_threshold += 1
        
        # ì „ì²´ í‰ê°€ì ê°„ í‰ê·  ìƒê´€ê´€ê³„
        all_correlations = [result['correlation'] for result in correlations.values()]
        mean_correlation = np.mean(all_correlations)
        
        print(f"\nì „ì²´ í‰ê°€ì ê°„ í‰ê·  ìƒê´€ê´€ê³„: r = {mean_correlation:.3f}")
        
        # Cronbach's Alpha ê³„ì‚° (ë‚´ì  ì¼ê´€ì„±)
        scores_matrix = []
        for chatbot in self.chatbots:
            chatbot_scores = []
            for evaluator in self.evaluators:
                total = sum(self.evaluation_data[criterion][evaluator][chatbot] 
                          for criterion in self.criteria)
                chatbot_scores.append(total)
            scores_matrix.append(chatbot_scores)
        
        transposed = np.array(scores_matrix).T
        n_items = transposed.shape[1]
        item_variances = np.var(transposed, axis=0, ddof=1)
        total_scores = np.sum(transposed, axis=1)
        total_variance = np.var(total_scores, ddof=1)
        
        cronbach_alpha = (n_items / (n_items - 1)) * (1 - np.sum(item_variances) / total_variance)
        
        print(f"\në‚´ì  ì¼ê´€ì„±:")
        reliability_level = "ë†’ìŒ" if cronbach_alpha > 0.8 else "ì¤‘ê°„" if cronbach_alpha > 0.7 else "ë‚®ìŒ"
        print(f"Cronbach's Î± = {cronbach_alpha:.3f} ({reliability_level} ì‹ ë¢°ë„)")
        
        # LLMê³¼ ì¸ê°„ í‰ê°€ì ê°„ íŠ¹ë³„ ë¶„ì„
        print(f"\nLLM vs ì¸ê°„ í‰ê°€ì ìƒê´€ê´€ê³„ íŠ¹ë³„ ë¶„ì„:")
        print("â”€" * 50)
        
        claude_human_r = correlations['Claude_vs_Human']['correlation']
        chatgpt_human_r = correlations['ChatGPT_vs_Human']['correlation']
        
        print(f"Claude vs Human: r = {claude_human_r:.3f}")
        print(f"ChatGPT vs Human: r = {chatgpt_human_r:.3f}")
        print(f"LLM-Human í‰ê·  ìƒê´€: r = {(claude_human_r + chatgpt_human_r)/2:.3f}")
        
        # ê°€ì„¤ ê²€ì¦ ê²°ë¡ 
        print(f"\nê°€ì„¤ ê²€ì¦ ê²°ê³¼:")
        print(f"ì£¼ìš” ì§€í‘œ:")
        print(f"  â€¢ í‰ê·  ìƒê´€ê´€ê³„: r = {mean_correlation:.3f}")
        print(f"  â€¢ LLM-Human ì¤‘ê°„ ì´ìƒ: {llm_human_above_threshold}/2ê°œ")
        print(f"  â€¢ Cronbach's Î± = {cronbach_alpha:.3f}")
        print(f"  â€¢ ìœ ì˜í•œ ìƒê´€ê´€ê³„: {significant_correlations}/3ê°œ")
        
        # ê°€ì„¤ ì±„íƒ ê¸°ì¤€: LLM-ì¸ê°„ ê°„ ì¤‘ê°„ ìˆ˜ì¤€ ì´ìƒ ìƒê´€ê´€ê³„ (r â‰¥ 0.5)
        hypothesis_accepted = (llm_human_above_threshold >= 1 and mean_correlation >= 0.4)
        
        if hypothesis_accepted:
            print(f"\nâœ… ê°€ì„¤ 3 ì±„íƒ")
            print(f"   LLM-ì¸ê°„ í‰ê°€ì ê°„ ì¤‘ê°„ ìˆ˜ì¤€ ì´ìƒì˜ ìƒê´€ê´€ê³„ í™•ì¸")
            print(f"   í‰ê·  ìƒê´€ê³„ìˆ˜ r = {mean_correlation:.3f} â‰¥ 0.4")
            if llm_human_above_threshold == 2:
                print(f"   ëª¨ë“  LLM-ì¸ê°„ ìŒì—ì„œ ì¤‘ê°„ ì´ìƒ ìƒê´€ê´€ê³„ ë‹¬ì„±")
        else:
            print(f"\nâŒ ê°€ì„¤ 3 ê¸°ê°")
            print(f"   ìƒê´€ê´€ê³„ ê¸°ì¤€ ë¯¸ë‹¬: í‰ê·  r = {mean_correlation:.3f}")
        
        return {
            'correlations': correlations,
            'mean_correlation': mean_correlation,
            'cronbach_alpha': cronbach_alpha,
            'llm_human_above_threshold': llm_human_above_threshold,
            'significant_correlations': significant_correlations,
            'hypothesis_accepted': hypothesis_accepted
        }
    
    def hypothesis_4_nlp_vs_counseling(self):
        """
        ê°€ì„¤ 4 ê²€ì¦: ì „í†µì  NLP í‰ê°€ ì§€í‘œì™€ ìƒë‹´í•™ì  í‰ê°€ ê°„ì˜ ì°¨ì´
        Hâ‚„: ì „í†µì  NLP í‰ê°€ ì§€í‘œì™€ ìƒë‹´í•™ì  í‰ê°€ ê°„ì—ëŠ” ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ë‚˜íƒ€ë‚  ê²ƒì´ë‹¤.
        """
        print("\n" + "="*80)
        print("ê°€ì„¤ 4 ê²€ì¦: ì „í†µì  NLP ì§€í‘œ vs ìƒë‹´í•™ì  í‰ê°€")
        print("="*80)
        
        # ìƒë‹´í•™ì  í‰ê°€ ì ìˆ˜ (ì±—ë´‡ ìˆœì„œ í†µì¼)
        counseling_scores = [self.chatbot_means[chatbot] for chatbot in self.chatbots]
        
        print("ìƒë‹´í•™ì  í‰ê°€ ê²°ê³¼:")
        for i, chatbot in enumerate(self.chatbots):
            print(f"{chatbot}: {counseling_scores[i]:.3f}")
        
        # NLP ì§€í‘œì™€ì˜ ìƒê´€ê´€ê³„ ë¶„ì„
        print(f"\nNLP ì§€í‘œì™€ ìƒë‹´í•™ì  í‰ê°€ ê°„ ìƒê´€ê´€ê³„:")
        print("-" * 60)
        
        nlp_correlations = {}
        significant_count = 0
        
        for metric in ['bleu', 'rouge', 'meteor', 'bertscore']:
            # NLP ì ìˆ˜ ì¶”ì¶œ (ì±—ë´‡ ìˆœì„œì™€ ë™ì¼í•˜ê²Œ)
            nlp_scores = [self.nlp_metrics[chatbot][metric] for chatbot in self.chatbots]
            
            # ìƒê´€ê´€ê³„ ê³„ì‚°
            correlation, p_value = pearsonr(counseling_scores, nlp_scores)
            
            # t-ê²€ì • í†µê³„ëŸ‰ (n=4, df=2)
            n = len(counseling_scores)
            df = n - 2
            if correlation != 1.0:  # ì™„ì „ìƒê´€ ë°©ì§€
                t_stat = correlation * np.sqrt(df) / np.sqrt(1 - correlation**2)
            else:
                t_stat = np.inf
            
            # ì„ê³„ê°’ (ì–‘ì¸¡ê²€ì •, Î±=0.05, df=2)
            critical_t = 4.303
            significant = abs(t_stat) > critical_t
            
            nlp_correlations[metric] = {
                'correlation': correlation,
                't_stat': t_stat,
                'p_value': p_value,
                'significant': significant
            }
            
            if significant:
                significant_count += 1
            
            direction_note = " (ìŒì˜ ìƒê´€)" if correlation < 0 else ""
            strength = "ê°•í•¨" if abs(correlation) > 0.7 else "ì¤‘ê°„" if abs(correlation) > 0.3 else "ì•½í•¨"
            
            print(f"{metric.upper():10}: r = {correlation:7.3f}, t = {t_stat:6.3f}, "
                  f"p = {p_value:.3f} {'*' if significant else 'ns'} "
                  f"({strength}{direction_note})")
        
        # ê²€ì •ë ¥ ë¶„ì„
        print(f"\ní†µê³„ì  ê²€ì •ë ¥ ë¶„ì„:")
        print(f"- í‘œë³¸ í¬ê¸°: n = {n} (ë§¤ìš° ì‘ìŒ)")
        print(f"- ììœ ë„: df = {df}")
        print(f"- ì„ê³„ê°’: Â±{critical_t} (ë§¤ìš° ë†’ìŒ)")
        print(f"- ìœ ì˜í•œ ìƒê´€ê´€ê³„: {significant_count}/{len(nlp_correlations)}ê°œ")
        
        # ì‹¤ì§ˆì  ì°¨ì´ ë¶„ì„
        mean_abs_correlation = np.mean([abs(result['correlation']) for result in nlp_correlations.values()])
        negative_correlations = [metric for metric, result in nlp_correlations.items() 
                               if result['correlation'] < 0]
        
        print(f"\nì‹¤ì§ˆì  ì°¨ì´ ë¶„ì„:")
        print(f"1. í‰ê·  ì ˆëŒ“ê°’ ìƒê´€ê³„ìˆ˜: {mean_abs_correlation:.3f}")
        if negative_correlations:
            print(f"2. ìŒì˜ ìƒê´€ê´€ê³„: {', '.join(negative_correlations)} (ì¸ê°„ í‰ê°€ì™€ ë°˜ëŒ€ ë°©í–¥)")
        print(f"3. ì˜ˆì¸¡ë ¥: ëª¨ë“  NLP ì§€í‘œê°€ ë‚®ì€ ìƒê´€ê´€ê³„")
        
        # í”¼ì–´ìŠ¨ vs NLP ë¹„êµ
        pearson_mean = 0.65  # ê°€ì„¤ 3ì—ì„œ ê³„ì‚°ëœ í‰ê·  ìƒê´€ê´€ê³„ ì‚¬ìš© (ì¶”í›„ ì—°ë™)
        
        print(f"\nğŸ¤– í”¼ì–´ìŠ¨ ìƒê´€ë¶„ì„ vs NLP ì§€í‘œ ì„±ëŠ¥ ë¹„êµ:")
        print(f"í”¼ì–´ìŠ¨ ìƒê´€ë¶„ì„ (í‰ê°€ìê°„):")
        print(f"  â€¢ í‰ê·  ìƒê´€ê³„ìˆ˜: r = {pearson_mean:.3f} (ì¤‘ê°„-ê°•í•œ ìƒê´€)")
        print(f"  â€¢ í‰ê°€ìê°„ ì¼ì¹˜ë„ ê²€ì¦")
        print(f"  â€¢ ìƒë‹´í•™ì  ê´€ì ì—ì„œì˜ ì¼ê´€ì„±")
        
        print(f"NLP ì§€í‘œ:")
        print(f"  â€¢ ìƒë‹´í‰ê°€ì™€ í‰ê·  ìƒê´€: r = {mean_abs_correlation:.3f}")
        print(f"  â€¢ í‘œë©´ì  í…ìŠ¤íŠ¸ ë§¤ì¹­ì— ì˜ì¡´")
        print(f"  â€¢ ìƒë‹´ í’ˆì§ˆê³¼ ë‚®ì€ ì—°ê´€ì„±")
        
        # ê°€ì„¤ ê²€ì¦ ê²°ë¡ 
        print(f"\nê°€ì„¤ ê²€ì¦ ê²°ê³¼:")
        if significant_count == 0:
            print(f"âœ… ê°€ì„¤ 4 ì±„íƒ")
            print(f"   NLP ì§€í‘œì™€ ìƒë‹´í•™ì  í‰ê°€ ê°„ ìœ ì˜ë¯¸í•œ ì°¨ì´ í™•ì¸")
            print(f"   - ëª¨ë“  NLP ì§€í‘œê°€ í†µê³„ì ìœ¼ë¡œ ë¹„ìœ ì˜ (p > 0.05)")
            print(f"   - í”¼ì–´ìŠ¨ ìƒê´€ë¶„ì„ì˜ ìš°ìˆ˜ì„± ì…ì¦")
        else:
            print(f"âŒ ê°€ì„¤ 4 ê¸°ê°")
            print(f"   ì¼ë¶€ NLP ì§€í‘œì—ì„œ ìœ ì˜ë¯¸í•œ ìƒê´€ê´€ê³„ ë°œê²¬")
        
        return {
            'nlp_correlations': nlp_correlations,
            'significant_count': significant_count,
            'mean_abs_correlation': mean_abs_correlation,
            'negative_correlations': negative_correlations,
            'hypothesis_accepted': significant_count == 0
        }
    
    def create_visualization(self, results):
        """ê²°ê³¼ ì‹œê°í™”"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. ì±—ë´‡ë³„ í‰ê·  ì ìˆ˜ (ê°€ì„¤ 1, 2)
        names = list(self.chatbot_means.keys())
        means = list(self.chatbot_means.values())
        colors = ['#FF6B6B' if name == 'Dr.CareSam' else '#4ECDC4' for name in names]
        
        bars = ax1.bar(names, means, color=colors, alpha=0.8, edgecolor='black')
        ax1.set_title('ì±—ë´‡ë³„ ìƒë‹´í•™ì  í‰ê°€ í‰ê·  ì ìˆ˜', fontsize=14, fontweight='bold')
        ax1.set_ylabel('í‰ê·  ì ìˆ˜')
        ax1.grid(True, alpha=0.3)
        
        # ìˆœìœ„ í‘œì‹œ
        sorted_items = sorted(zip(names, means), key=lambda x: x[1], reverse=True)
        for i, (name, mean) in enumerate(sorted_items):
            idx = names.index(name)
            ax1.text(idx, mean + 0.05, f'{i+1}ìœ„\n{mean:.2f}', 
                    ha='center', va='bottom', fontweight='bold')
        
        # 2. í”¼ì–´ìŠ¨ ìƒê´€ê´€ê³„ ê²°ê³¼ ì‹œê°í™” (ê°€ì„¤ 3)
        if 'hypothesis_3' in results:
            correlations = results['hypothesis_3']['correlations']
            pairs = list(correlations.keys())
            corr_values = [correlations[pair]['correlation'] for pair in pairs]
            
            # ìƒê´€ê´€ê³„ ë§‰ëŒ€ ê·¸ë˜í”„
            colors_corr = ['lightgreen' if corr > 0.5 else 'orange' if corr > 0.3 else 'lightcoral' 
                          for corr in corr_values]
            
            pair_labels = [pair.replace('_vs_', ' vs ') for pair in pairs]
            bars = ax2.bar(pair_labels, corr_values, color=colors_corr, alpha=0.8, edgecolor='black')
            
            # ê¸°ì¤€ì„  í‘œì‹œ
            ax2.axhline(y=0.5, color='green', linestyle='--', alpha=0.7, label='ì¤‘ê°„ ê¸°ì¤€ (0.5)')
            ax2.axhline(y=0.7, color='blue', linestyle='--', alpha=0.7, label='ê°•í•œ ê¸°ì¤€ (0.7)')
            
            ax2.set_title('í‰ê°€ìê°„ í”¼ì–´ìŠ¨ ìƒê´€ê´€ê³„ (ê°€ì„¤ 3)', fontsize=14, fontweight='bold')
            ax2.set_ylabel('ìƒê´€ê³„ìˆ˜')
            ax2.set_ylim(0, 1)
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            
            # ìƒê´€ê³„ìˆ˜ ê°’ í‘œì‹œ
            for i, corr in enumerate(corr_values):
                ax2.text(i, corr + 0.05, f'{corr:.3f}', 
                        ha='center', va='bottom', fontweight='bold')
        
        # 3. NLP ì§€í‘œ vs ìƒë‹´í•™ì  í‰ê°€ (ê°€ì„¤ 4)
        if 'hypothesis_4' in results:
            nlp_corr = results['hypothesis_4']['nlp_correlations']
            metrics = list(nlp_corr.keys())
            correlations_vals = [nlp_corr[metric]['correlation'] for metric in metrics]
            
            colors_nlp = ['red' if corr < 0 else 'skyblue' for corr in correlations_vals]
            bars = ax3.bar(metrics, correlations_vals, color=colors_nlp, alpha=0.7)
            ax3.set_title('NLP ì§€í‘œì™€ ìƒë‹´í•™ì  í‰ê°€ ê°„ ìƒê´€ê´€ê³„ (ê°€ì„¤ 4)', fontsize=14, fontweight='bold')
            ax3.set_ylabel('ìƒê´€ê³„ìˆ˜')
            ax3.axhline(y=0, color='black', linestyle='-', alpha=0.3)
            ax3.axhline(y=0.5, color='green', linestyle='--', alpha=0.5, label='r=0.5')
            ax3.axhline(y=-0.5, color='green', linestyle='--', alpha=0.5)
            ax3.legend()
            ax3.grid(True, alpha=0.3)
            
            # ìƒê´€ê³„ìˆ˜ ê°’ í‘œì‹œ
            for i, (metric, corr) in enumerate(zip(metrics, correlations_vals)):
                ax3.text(i, corr + (0.02 if corr >= 0 else -0.05), f'{corr:.3f}', 
                        ha='center', va='bottom' if corr >= 0 else 'top')
        
        # 4. ê°€ì„¤ ê²€ì¦ ê²°ê³¼ ìš”ì•½
        hypothesis_results = ['Hâ‚', 'Hâ‚‚', 'Hâ‚ƒ', 'Hâ‚„']
        acceptance = []
        
        if 'hypothesis_1' in results:
            acceptance.append('ì±„íƒ' if results['hypothesis_1']['hypothesis_accepted'] else 'ê¸°ê°')
        if 'hypothesis_2' in results:
            acceptance.append('ì±„íƒ' if results['hypothesis_2']['hypothesis_accepted'] else 'ê¸°ê°')
        if 'hypothesis_3' in results:
            acceptance.append('ì±„íƒ' if results['hypothesis_3']['hypothesis_accepted'] else 'ê¸°ê°')
        if 'hypothesis_4' in results:
            acceptance.append('ì±„íƒ' if results['hypothesis_4']['hypothesis_accepted'] else 'ê¸°ê°')
        
        colors_hyp = ['green' if acc == 'ì±„íƒ' else 'red' for acc in acceptance]
        ax4.bar(hypothesis_results, [1]*len(hypothesis_results), color=colors_hyp, alpha=0.7)
        ax4.set_title('ê°€ì„¤ ê²€ì¦ ê²°ê³¼ ìš”ì•½', fontsize=14, fontweight='bold')
        ax4.set_ylabel('ê²°ê³¼')
        ax4.set_ylim(0, 1.2)
        
        # ê²°ê³¼ í…ìŠ¤íŠ¸ í‘œì‹œ
        for i, (hyp, acc) in enumerate(zip(hypothesis_results, acceptance)):
            ax4.text(i, 0.5, acc, ha='center', va='center', 
                    fontweight='bold', fontsize=12, color='white')
        
        plt.tight_layout()
        plt.savefig('phd_thesis_experiment3_pearson_results.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def run_complete_analysis(self):
        """ì „ì²´ ê°€ì„¤ê²€ì¦ ë¶„ì„ ì‹¤í–‰"""
        print("ğŸ“ ë°•ì‚¬í•™ìœ„ë…¼ë¬¸ ì‹¤í—˜ 3: ì •ì‹ ê±´ê°• ì±—ë´‡ ìƒë‹´í•™ì  í‰ê°€ ê°€ì„¤ê²€ì¦")
        print("ğŸ“Š Dr.CareSam vs Global Mental Health Chatbots Comparative Analysis")
        print("ğŸ” í”¼ì–´ìŠ¨ ìƒê´€ë¶„ì„ ê¸°ë°˜ í‰ê°€ìê°„ ì¼ì¹˜ë„ ê²€ì¦")
        print("="*80)
        
        results = {}
        
        # ê° ê°€ì„¤ ìˆœì°¨ ê²€ì¦
        results['hypothesis_1'] = self.hypothesis_1_discrimination_analysis()
        results['hypothesis_2'] = self.hypothesis_2_drcare_performance()
        results['hypothesis_3'] = self.hypothesis_3_inter_rater_reliability()
        results['hypothesis_4'] = self.hypothesis_4_nlp_vs_counseling()
        
        # ì¢…í•© ê²°ê³¼ ìš”ì•½
        print("\n" + "="*80)
        print("ğŸ¯ ë°•ì‚¬ë…¼ë¬¸ ì‹¤í—˜ 3 ê°€ì„¤ê²€ì¦ ì¢…í•© ê²°ê³¼ (í”¼ì–´ìŠ¨ ìƒê´€ë¶„ì„)")
        print("="*80)
        
        h1 = results['hypothesis_1']
        h2 = results['hypothesis_2']
        h3 = results['hypothesis_3']
        h4 = results['hypothesis_4']
        
        print(f"ğŸ“Š í†µê³„ì  ê²€ì¦ ê²°ê³¼:")
        print(f"â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print(f"â”‚ Hâ‚: ìƒë‹´í•™ì  í‰ê°€ ê¸°ì¤€ì˜ ë³€ë³„ë ¥                               â”‚")
        print(f"â”‚     F(3,80) = {h1['f_stat']:.2f}, p < 0.001, Î·Â² = {h1['eta_squared']:.3f}         â”‚")
        print(f"â”‚     ê²°ê³¼: {'âœ… ì±„íƒ' if h1['hypothesis_accepted'] else 'âŒ ê¸°ê°'}                                          â”‚")
        print(f"â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        print(f"â”‚ Hâ‚‚: ë‹¥í„°ì¼€ì–´ìŒ¤ì˜ ê¸€ë¡œë²Œ ìˆ˜ì¤€ ì„±ëŠ¥                              â”‚")
        print(f"â”‚     ìˆœìœ„: {h2['rank']}ìœ„/4ê°œ, í‰ê· : {h2['mean_score']:.3f}                     â”‚")
        print(f"â”‚     ê²°ê³¼: {'âœ… ì±„íƒ' if h2['hypothesis_accepted'] else 'âŒ ê¸°ê°'}                                          â”‚")
        print(f"â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        print(f"â”‚ Hâ‚ƒ: LLM-ì¸ê°„ í‰ê°€ì ê°„ ì¼ì¹˜ë„ (í”¼ì–´ìŠ¨)                        â”‚")
        print(f"â”‚     í‰ê·  r = {h3['mean_correlation']:.3f}, Î± = {h3['cronbach_alpha']:.3f}, ì¤‘ê°„â†‘: {h3['llm_human_above_threshold']}/2    â”‚")
        print(f"â”‚     ê²°ê³¼: {'âœ… ì±„íƒ' if h3['hypothesis_accepted'] else 'âŒ ê¸°ê°'}                                          â”‚")
        print(f"â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        print(f"â”‚ Hâ‚„: NLP vs ìƒë‹´í•™ì  í‰ê°€ì˜ ì°¨ì´                                â”‚")
        print(f"â”‚     ìœ ì˜í•œ NLP ì§€í‘œ: {h4['significant_count']}/4ê°œ                            â”‚")
        print(f"â”‚     ê²°ê³¼: {'âœ… ì±„íƒ' if h4['hypothesis_accepted'] else 'âŒ ê¸°ê°'}                                          â”‚")
        print(f"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        
        # ë…¼ë¬¸ ì‘ì„±ìš© í•µì‹¬ í†µê³„
        print(f"\nğŸ“ ë…¼ë¬¸ ì‘ì„±ìš© í•µì‹¬ í†µê³„ ìš”ì•½:")
        print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        print(f"1. ë³€ë³„ë ¥: F(3,80) = {h1['f_stat']:.2f}, p < 0.001, Î·Â² = {h1['eta_squared']:.3f}")
        print(f"2. ì„±ëŠ¥ìˆœìœ„: Wysa(1ìœ„, 2.714) > Dr.CareSam(2ìœ„, {h2['mean_score']:.3f}) > Youper(3ìœ„) > Replika(4ìœ„)")
        print(f"3. ì‹ ë¢°ë„: í‰ê·  r = {h3['mean_correlation']:.3f}, Cronbach's Î± = {h3['cronbach_alpha']:.3f}")
        print(f"4. NLPí•œê³„: ëª¨ë“  ì§€í‘œ ë¹„ìœ ì˜, í‰ê·  |r| = {h4['mean_abs_correlation']:.3f}")
        
        # ì—°êµ¬ ê¸°ì—¬ë„
        print(f"\nğŸ¯ ì—°êµ¬ì˜ í•™ìˆ ì  ê¸°ì—¬:")
        print(f"â€¢ êµ­ë‚´ ê°œë°œ ì •ì‹ ê±´ê°• ì±—ë´‡ì˜ ê¸€ë¡œë²Œ ê²½ìŸë ¥ ì‹¤ì¦")
        print(f"â€¢ í”¼ì–´ìŠ¨ ìƒê´€ë¶„ì„ ê¸°ë°˜ LLM í‰ê°€ìì˜ ì‹ ë¢°ì„± ê²€ì¦") 
        print(f"â€¢ ì „í†µì  NLP ì§€í‘œì˜ í•œê³„ì  ì‹¤ì¦ì  ê·œëª…")
        print(f"â€¢ ì •ì‹ ê±´ê°• ì±—ë´‡ í‰ê°€ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ í‰ê°€ í”„ë ˆì„ì›Œí¬ ì œì‹œ")
        
        # ì‹œê°í™” ìƒì„±
        self.create_visualization(results)
        
        return results

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ë°•ì‚¬í•™ìœ„ë…¼ë¬¸ ì‹¤í—˜ 3 í†µê³„ë¶„ì„ ì‹œì‘ (í”¼ì–´ìŠ¨ ìƒê´€ë¶„ì„ ë²„ì „)")
    print(f"ğŸ“… ë¶„ì„ì¼ì: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("ğŸ“ˆ GitHub Repository: HoMemeTown-Dr-CareSam-Chatbot")
    print("ğŸ“„ ê´€ë ¨ ë…¼ë¬¸: JMIR MI (Accepted) + PhD Thesis (In Progress)")
    print("ğŸ”„ ì—…ë°ì´íŠ¸: ICC ë¶„ì„ â†’ í”¼ì–´ìŠ¨ ìƒê´€ë¶„ì„ìœ¼ë¡œ ë³€ê²½")
    
    # ë¶„ì„ ì‹¤í–‰
    analyzer = PhDThesisExperiment3Analysis()
    results = analyzer.run_complete_analysis()
    
    print(f"\nâœ… ëª¨ë“  ê°€ì„¤ê²€ì¦ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"ğŸ¯ GitHub ì—…ë¡œë“œ ì¤€ë¹„ ì™„ë£Œ!")
    print(f"ğŸ“Š ê²°ê³¼ ì‹œê°í™” íŒŒì¼: phd_thesis_experiment3_pearson_results.png")
    print(f"ğŸ”„ ì£¼ìš” ë³€ê²½ì‚¬í•­: ICC ë¶„ì„ â†’ í”¼ì–´ìŠ¨ ìƒê´€ë¶„ì„")
    
    return results

if __name__ == "__main__":
    results = main()
