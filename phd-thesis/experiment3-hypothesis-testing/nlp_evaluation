import numpy as np
import scipy.stats as stats
from typing import Dict, List, Tuple
import math

class NLPMetricsCalculator:
    """
    ì „í†µì  NLP ì§€í‘œ ê³„ì‚° ë° í†µê³„ì  ìœ ì˜ì„± ë¶„ì„ í´ë˜ìŠ¤
    """
    
    def __init__(self):
        # ì‹¤ì œ ëŒ€í™” ë°ì´í„°
        self.dialogues = {
            "Wysa": "Let's talk about that. Go on... I'm here to help you feel more in control. A little anxiety can spur us to action. Too much of it can be paralyzing. Is yours mostly in the mind, or is it affecting you physically too?",
            
            "ë‹¥í„°ì¼€ì–´ìŒ¤": "Ah, presentations can definitely stir up the butterflies in the stomach, can't they? Let's turn those nervous jitters into a power source! Imagine all that energy being channeled into enthusiasm for your topic. What's your presentation about? Maybe I can share a joke or two to lighten up the mood!",
            
            "Youper": "I'm sorry to hear that you're feeling anxious. It can be tough to manage those feelings. Would you like to explore a positive technique that might help ease your anxiety? For instance, we could start with gratitude journaling. What are some things, no matter how small, that you feel grateful for today?",
            
            "Replika": "Sorry to hear that. Can you tell me what's on your mind? Yeah, public speaking can be intimidating. Have you prepared well for the presentation?"
        }
        
        # ì´ìƒì ì¸ ì°¸ì¡° ì‘ë‹µ (Ground Truth)
        self.reference_responses = [
            "I understand you're feeling anxious about your presentation. Let's work together to help you feel more confident and prepared.",
            "It's completely normal to feel nervous before presenting. I'm here to support you through this.",
            "Anxiety before presentations is very common. Let me help you develop some coping strategies.",
            "I can see this is causing you stress. Would you like to explore some techniques to manage these feelings?"
        ]
        
        # ì‹¤ì œ NLP ì§€í‘œ ê²°ê³¼ ë°ì´í„° (ìœ„ ëŒ€í™”ë“¤ë¡œë¶€í„° ê³„ì‚°ëœ ê²°ê³¼)
        self.nlp_results = {
            "Youper": {"bleu": 0.144, "rouge": 0.254, "meteor": 0.310, "bertscore": 0.288, "average": 0.249},
            "Wysa": {"bleu": 0.141, "rouge": 0.250, "meteor": 0.290, "bertscore": 0.270, "average": 0.238},
            "Replika": {"bleu": 0.000, "rouge": 0.150, "meteor": 0.227, "bertscore": 0.280, "average": 0.164},
            "ë‹¥í„°ì¼€ì–´ìŒ¤": {"bleu": 0.040, "rouge": 0.129, "meteor": 0.159, "bertscore": 0.184, "average": 0.128}
        }
        
        # ì¸ê°„ í‰ê°€ ê²°ê³¼ (ìƒë‹´í•™ì  í‰ê°€)
        self.human_evaluation = {
            "Wysa": 2.71,
            "ë‹¥í„°ì¼€ì–´ìŒ¤": 2.38,
            "Youper": 2.29,
            "Replika": 1.81
        }
        
        self.chatbots = ["Wysa", "ë‹¥í„°ì¼€ì–´ìŒ¤", "Youper", "Replika"]
        self.metrics = ['bleu', 'rouge', 'meteor', 'bertscore', 'average']
        self.metric_names = ['BLEU', 'ROUGE', 'METEOR', 'BERTScore', 'í‰ê· ']

    def calculate_bleu_score(self, reference: str, candidate: str) -> float:
        """
        BLEU ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨ ë²„ì „)
        ì‹¤ì œë¡œëŠ” nltk.translate.bleu_score ì‚¬ìš© ê¶Œì¥
        """
        from collections import Counter
        
        # ê°„ë‹¨í•œ n-gram ê¸°ë°˜ ê³„ì‚° (1-gram ~ 4-gram)
        ref_tokens = reference.lower().split()
        cand_tokens = candidate.lower().split()
        
        if len(cand_tokens) == 0:
            return 0.0
            
        # 1-gram precision
        ref_1grams = Counter(ref_tokens)
        cand_1grams = Counter(cand_tokens)
        
        common_1grams = sum((ref_1grams & cand_1grams).values())
        precision_1 = common_1grams / len(cand_tokens) if len(cand_tokens) > 0 else 0
        
        # Brevity penalty ê°„ë‹¨ ë²„ì „
        bp = min(1.0, len(cand_tokens) / len(ref_tokens)) if len(ref_tokens) > 0 else 0
        
        return bp * precision_1

    def calculate_rouge_score(self, reference: str, candidate: str) -> float:
        """
        ROUGE-L ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨ ë²„ì „)
        ì‹¤ì œë¡œëŠ” rouge-score ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê¶Œì¥
        """
        ref_tokens = set(reference.lower().split())
        cand_tokens = set(candidate.lower().split())
        
        if len(ref_tokens) == 0:
            return 0.0
            
        # Recall ê¸°ë°˜ ê³„ì‚°
        common_tokens = ref_tokens.intersection(cand_tokens)
        recall = len(common_tokens) / len(ref_tokens)
        
        return recall

    def calculate_meteor_score(self, reference: str, candidate: str) -> float:
        """
        METEOR ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨ ë²„ì „)
        ì‹¤ì œë¡œëŠ” nltk.translate.meteor_score ì‚¬ìš© ê¶Œì¥
        """
        ref_tokens = reference.lower().split()
        cand_tokens = candidate.lower().split()
        
        if len(cand_tokens) == 0:
            return 0.0
            
        # ë‹¨ì–´ ë§¤ì¹­ ê¸°ë°˜ ê³„ì‚°
        matches = sum(1 for token in cand_tokens if token in ref_tokens)
        
        precision = matches / len(cand_tokens) if len(cand_tokens) > 0 else 0
        recall = matches / len(ref_tokens) if len(ref_tokens) > 0 else 0
        
        if precision + recall == 0:
            return 0.0
            
        f_score = 2 * precision * recall / (precision + recall)
        return f_score

    def calculate_bertscore(self, reference: str, candidate: str) -> float:
        """
        BERTScore ê³„ì‚° (ëª¨ì˜ ë²„ì „)
        ì‹¤ì œë¡œëŠ” bert-score ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© í•„ìš”
        """
        # ì‹¤ì œ êµ¬í˜„ì„ ìœ„í•´ì„œëŠ” transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ BERT ëª¨ë¸ í•„ìš”
        # ì—¬ê¸°ì„œëŠ” ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ê°„ë‹¨ ê³„ì‚°
        
        ref_tokens = set(reference.lower().split())
        cand_tokens = set(candidate.lower().split())
        
        if len(ref_tokens) == 0 or len(cand_tokens) == 0:
            return 0.0
            
        # Jaccard ìœ ì‚¬ë„ë¡œ ê·¼ì‚¬
        intersection = len(ref_tokens.intersection(cand_tokens))
        union = len(ref_tokens.union(cand_tokens))
        
        return intersection / union if union > 0 else 0.0

    def calculate_correlation(self, x: List[float], y: List[float]) -> Dict:
        """
        ìƒê´€ê´€ê³„ ë¶„ì„ ë° í†µê³„ì  ìœ ì˜ì„± ê²€ì •
        """
        n = len(x)
        if n < 3:
            print("âš ï¸ ê²½ê³ : ìƒ˜í”Œ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŒ (n < 3)")
            return {"r": np.nan, "t_stat": np.nan, "p_value": np.nan, "significant": False}
        
        # í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ ê³„ì‚°
        r, p_value = stats.pearsonr(x, y)
        
        # t-ê²€ì • í†µê³„ëŸ‰ ê³„ì‚°
        t_stat = r * math.sqrt((n - 2) / (1 - r * r)) if abs(r) < 1 else np.inf
        
        # ììœ ë„
        df = n - 2
        
        # ì„ê³„ê°’ (ì–‘ì¸¡ê²€ì •, Î±=0.05)
        critical_values = {1: 12.706, 2: 4.303, 3: 3.182, 4: 2.776}
        critical_t = critical_values.get(df, 2.776)
        
        # í†µê³„ì  ìœ ì˜ì„±
        significant = abs(t_stat) > critical_t
        
        return {
            "r": r,
            "t_stat": t_stat,
            "p_value": p_value,
            "critical_t": critical_t,
            "df": df,
            "significant": significant
        }

    def calculate_required_sample_size(self, target_r: float, alpha: float = 0.05, power: float = 0.8) -> int:
        """
        ê²€ì •ë ¥ ë¶„ì„: í•„ìš”í•œ ìƒ˜í”Œ í¬ê¸° ê³„ì‚°
        """
        # Cohenì˜ ê³µì‹ ê¸°ë°˜ ê·¼ì‚¬ ê³„ì‚°
        z_alpha = stats.norm.ppf(1 - alpha/2)  # ì–‘ì¸¡ê²€ì •
        z_beta = stats.norm.ppf(power)
        
        # Fisher's z transformation
        fisher_z = 0.5 * math.log((1 + target_r) / (1 - target_r))
        
        n = ((z_alpha + z_beta) / fisher_z) ** 2 + 3
        return math.ceil(n)

    def analyze_nlp_correlation(self):
        """
        NLP ì§€í‘œì™€ ì¸ê°„ í‰ê°€ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„
        """
        print("ğŸ“Š ì „í†µì  NLP ì§€í‘œ í†µê³„ì  ìœ ì˜ì„± ë¶„ì„")
        print("=" * 50)
        
        print(f"ğŸ” ë°ì´í„° ê°œìš”:")
        print(f"- ì±—ë´‡ ìˆ˜: {len(self.chatbots)}ê°œ")
        print(f"- NLP ì§€í‘œ: {len(self.metrics)}ê°œ (BLEU, ROUGE, METEOR, BERTScore, Average)")
        print(f"- ììœ ë„: n-2 = {len(self.chatbots)-2} (n={len(self.chatbots)} ì±—ë´‡)")
        
        # ì¸ê°„ í‰ê°€ ì ìˆ˜ ì •ë ¬
        human_scores = [self.human_evaluation[bot] for bot in self.chatbots]
        
        print("\nğŸ“ˆ ì¸ê°„ í‰ê°€ vs NLP ì§€í‘œ ìƒê´€ê´€ê³„ ë¶„ì„:")
        print("-" * 45)
        
        correlation_results = {}
        
        for metric, metric_name in zip(self.metrics, self.metric_names):
            nlp_scores = [self.nlp_results[bot][metric] for bot in self.chatbots]
            result = self.calculate_correlation(human_scores, nlp_scores)
            
            correlation_results[metric] = result
            
            print(f"\n{metric_name} ë¶„ì„:")
            print(f"  ìƒê´€ê³„ìˆ˜ (r): {result['r']:.3f}")
            print(f"  t-í†µê³„ëŸ‰: {result['t_stat']:.3f}")
            print(f"  ì„ê³„ê°’ (Î±=0.05): Â±{result['critical_t']:.3f}")
            print(f"  p-value: {'<' if result['p_value'] < 0.05 else 'â‰ˆ'} {result['p_value']:.3f}")
            print(f"  í†µê³„ì  ìœ ì˜ì„±: {'âœ… ìœ ì˜í•¨' if result['significant'] else 'âŒ ìœ ì˜í•˜ì§€ ì•ŠìŒ'}")
            
            if result['r'] < 0:
                print(f"  âš ï¸ ì£¼ì˜: ìŒì˜ ìƒê´€ê´€ê³„ (ì¸ê°„í‰ê°€ì™€ ë°˜ëŒ€ ê²½í–¥)")
        
        # ì „ì²´ ë¶„ì„ ìš”ì•½
        print("\nğŸ“Š í†µê³„ì  ìœ ì˜ì„± ì¢…í•© ë¶„ì„:")
        print("-" * 45)
        
        significant_metrics = [metric for metric, result in correlation_results.items() if result['significant']]
        non_significant_metrics = [metric for metric, result in correlation_results.items() if not result['significant']]
        
        print(f"ìœ ì˜í•œ ì§€í‘œ: {len(significant_metrics)}ê°œ - {', '.join(significant_metrics)}")
        print(f"ë¹„ìœ ì˜í•œ ì§€í‘œ: {len(non_significant_metrics)}ê°œ - {', '.join(non_significant_metrics)}")
        
        # ìƒ˜í”Œ í¬ê¸°ì˜ í•œê³„
        print("\nâš ï¸ í†µê³„ì  ê²€ì •ë ¥ í•œê³„:")
        print("-" * 30)
        print("â€¢ ìƒ˜í”Œ í¬ê¸°: n=4 (ë§¤ìš° ì‘ìŒ)")
        print("â€¢ ììœ ë„: df=2 (ê²€ì •ë ¥ ë¶€ì¡±)")
        print("â€¢ ì„ê³„ê°’: Â±4.303 (ë§¤ìš° ë†’ìŒ)")
        print("â€¢ ê²°ë¡ : í†µê³„ì  ìœ ì˜ì„± ë‹¬ì„± ì–´ë ¤ì›€")
        
        # Power Analysis
        print("\nğŸ”‹ ê²€ì •ë ¥ ë¶„ì„ (Power Analysis):")
        print("-" * 35)
        
        target_correlations = [0.3, 0.5, 0.7, 0.9]
        print("ìƒê´€ê³„ìˆ˜ë³„ í•„ìš” ìƒ˜í”Œ í¬ê¸° (power=0.8):")
        for r in target_correlations:
            required_n = self.calculate_required_sample_size(r)
            print(f"  r={r}: ìµœì†Œ {required_n}ê°œ ì±—ë´‡ í•„ìš”")
        
        # ê²°ê³¼ í•´ì„
        print("\nğŸ¯ í˜„ì¬ ì—°êµ¬ ê²°ê³¼ í•´ì„:")
        print("-" * 30)
        print("1. í†µê³„ì  ìœ ì˜ì„±:")
        print("   â€¢ ëŒ€ë¶€ë¶„ NLP ì§€í‘œê°€ ë¹„ìœ ì˜í•¨ (p > 0.05)")
        print("   â€¢ ìƒ˜í”Œ í¬ê¸° ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ê²€ì •ë ¥ ë¶€ì¡±")
        print("   â€¢ 4ê°œ ì±—ë´‡ìœ¼ë¡œëŠ” í†µê³„ì  ê²°ë¡  ë„ì¶œ ì œí•œì ")
        
        print("\n2. ì‹¤ìš©ì  ì˜ë¯¸:")
        print("   â€¢ ìƒê´€ê³„ìˆ˜ í¬ê¸°ëŠ” ì—¬ì „íˆ ì˜ë¯¸ ìˆìŒ")
        print("   â€¢ ê²½í–¥ì„±ê³¼ íŒ¨í„´ ë¶„ì„ì€ ê°€ëŠ¥")
        print("   â€¢ íƒìƒ‰ì  ì—°êµ¬ë¡œì„œì˜ ê°€ì¹˜")
        
        print("\n3. ë…¼ë¬¸ ê¸°ìˆ  ë°©ì•ˆ:")
        print("   â€¢ 'í†µê³„ì  ìœ ì˜ì„± ë¶€ì¡±'ì„ í•œê³„ì ìœ¼ë¡œ ëª…ì‹œ")
        print("   â€¢ 'íƒìƒ‰ì  ë¶„ì„ ê²°ê³¼'ë¡œ ì œì‹œ")
        print("   â€¢ 'í–¥í›„ ëŒ€ê·œëª¨ ì—°êµ¬ í•„ìš”ì„±' ì–¸ê¸‰")
        
        return correlation_results

    def demonstrate_nlp_calculations(self):
        """
        ì‹¤ì œ ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ì™€ ëŒ€í™” ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ NLP ì§€í‘œ ê³„ì‚° ì‹œì—°
        """
        print("\nğŸ§® ì‹¤ì œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ NLP ì§€í‘œ ê³„ì‚°:")
        print("-" * 50)
        
        print("ğŸ“ ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ (ì°¸ì¡° ì‘ë‹µ):")
        for i, ref in enumerate(self.reference_responses, 1):
            print(f"  {i}. {ref}")
        
        print("\nğŸ¤– ê° ì±—ë´‡ì˜ ì‹¤ì œ ì‘ë‹µ:")
        for bot in self.chatbots:
            print(f"\n{bot}:")
            print(f"  \"{self.dialogues[bot]}\"")
        
        print("\nğŸ“Š ê° ì±—ë´‡ë³„ NLP ì§€í‘œ ê³„ì‚° ê³¼ì •:")
        print("-" * 45)
        
        # ê° ì±—ë´‡ì˜ ì‘ë‹µì„ ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ì™€ ë¹„êµ
        for bot in self.chatbots:
            print(f"\nğŸ” {bot} ë¶„ì„:")
            candidate = self.dialogues[bot]
            
            # ëª¨ë“  ì°¸ì¡° ì‘ë‹µê³¼ ë¹„êµí•˜ì—¬ ìµœê³  ì ìˆ˜ ì‚¬ìš© (ì¼ë°˜ì  ë°©ë²•)
            max_scores = {
                'bleu': 0,
                'rouge': 0, 
                'meteor': 0,
                'bertscore': 0
            }
            
            for ref in self.reference_responses:
                bleu = self.calculate_bleu_score(ref, candidate)
                rouge = self.calculate_rouge_score(ref, candidate)
                meteor = self.calculate_meteor_score(ref, candidate)
                bertscore = self.calculate_bertscore(ref, candidate)
                
                max_scores['bleu'] = max(max_scores['bleu'], bleu)
                max_scores['rouge'] = max(max_scores['rouge'], rouge)
                max_scores['meteor'] = max(max_scores['meteor'], meteor)
                max_scores['bertscore'] = max(max_scores['bertscore'], bertscore)
            
            # ê³„ì‚°ëœ ì ìˆ˜ ì¶œë ¥
            print(f"  ê³„ì‚°ëœ BLEU: {max_scores['bleu']:.3f}")
            print(f"  ê³„ì‚°ëœ ROUGE: {max_scores['rouge']:.3f}")
            print(f"  ê³„ì‚°ëœ METEOR: {max_scores['meteor']:.3f}")
            print(f"  ê³„ì‚°ëœ BERTScore: {max_scores['bertscore']:.3f}")
            
            # ì‹¤ì œ ë…¼ë¬¸ ê²°ê³¼ì™€ ë¹„êµ
            actual = self.nlp_results[bot]
            print(f"  ë…¼ë¬¸ BLEU: {actual['bleu']:.3f}")
            print(f"  ë…¼ë¬¸ ROUGE: {actual['rouge']:.3f}")
            print(f"  ë…¼ë¬¸ METEOR: {actual['meteor']:.3f}")
            print(f"  ë…¼ë¬¸ BERTScore: {actual['bertscore']:.3f}")
        
        print("\nğŸ’¡ ë‹¥í„°ì¼€ì–´ìŒ¤ì´ ë‚®ì€ ì ìˆ˜ë¥¼ ë°›ëŠ” ì´ìœ :")
        print("-" * 40)
        
        dr_caresam_response = self.dialogues["ë‹¥í„°ì¼€ì–´ìŒ¤"]
        print(f"ë‹¥í„°ì¼€ì–´ìŒ¤ ì‘ë‹µ:")
        print(f"  \"{dr_caresam_response}\"")
        
        print(f"\níŠ¹ì§• ë¶„ì„:")
        print(f"  âœ¨ ì°½ì˜ì  í‘œí˜„: 'butterflies in the stomach', 'nervous jitters'")
        print(f"  âœ¨ ê¸ì •ì  ë¦¬í”„ë ˆì´ë°: 'turn jitters into a power source'")
        print(f"  âœ¨ ìœ ë¨¸ ì œì•ˆ: 'Maybe I can share a joke or two'")
        print(f"  âœ¨ ê°œì¸í™”: 'What's your presentation about?'")
        
        print(f"\nê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ì™€ì˜ ì°¨ì´:")
        print(f"  âŒ ì§ì ‘ì  ê°ì • ì¸ì • ë¶€ì¡±: 'anxious', 'nervous' ë‹¨ì–´ ì—†ìŒ")
        print(f"  âŒ í‘œì¤€ ìƒë‹´ ìš©ì–´ ë¶€ì¡±: 'normal', 'common', 'techniques' ì—†ìŒ")
        print(f"  âŒ í‚¤ì›Œë“œ ê²¹ì¹¨ ìµœì†Œ: ì°¸ì¡° ì‘ë‹µê³¼ ì™„ì „íˆ ë‹¤ë¥¸ ì ‘ê·¼")
        
        print(f"\nğŸ¯ ê²°ë¡ :")
        print(f"  â€¢ NLP ì§€í‘œëŠ” 'ë‹¤ë¦„'ì„ 'ë‚˜ì¨'ìœ¼ë¡œ í‰ê°€")
        print(f"  â€¢ ì°½ì˜ì ì´ê³  íš¨ê³¼ì ì¸ ìƒë‹´ ì ‘ê·¼ì„ ì €í‰ê°€")
        print(f"  â€¢ í‘œì¤€í™”ëœ ì‘ë‹µë§Œì„ 'ì¢‹ì€' ì‘ë‹µìœ¼ë¡œ ì¸ì‹")

    def analyze_ground_truth_bias(self):
        """
        ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ì˜ í¸í–¥ì„± ë¶„ì„
        """
        print("\nğŸ¯ ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ í¸í–¥ì„± ë¶„ì„:")
        print("-" * 40)
        
        print("ğŸ“‹ ì°¸ì¡° ì‘ë‹µë“¤ì˜ ê³µí†µ íŒ¨í„´:")
        common_words = ['anxious', 'nervous', 'normal', 'common', 'help', 'support', 'techniques', 'feelings']
        
        for word in common_words:
            count = sum(1 for ref in self.reference_responses if word.lower() in ref.lower())
            if count > 0:
                print(f"  â€¢ '{word}': {count}/{len(self.reference_responses)} ì‘ë‹µì—ì„œ ì‚¬ìš©")
        
        print(f"\nğŸŒ ë¬¸í™”ì /ì–¸ì–´ì  í¸í–¥:")
        print(f"  â€¢ ì§ì„¤ì  í‘œí˜„ ì„ í˜¸ ('You are anxious')")
        print(f"  â€¢ ì„œêµ¬ì‹ ê°œì¸ì£¼ì˜ì  ì ‘ê·¼")
        print(f"  â€¢ ê°ì • ì¦‰ì‹œ ëª…ëª…í•˜ëŠ” ìŠ¤íƒ€ì¼")
        print(f"  â€¢ ë¹ ë¥¸ í•´ê²°ì±… ì œì‹œ ì§€í–¥")
        
        print(f"\nğŸš¨ ì´ê²ƒì´ í‰ê°€ì— ë¯¸ì¹˜ëŠ” ì˜í–¥:")
        print(f"  â€¢ ë‹¤ì–‘í•œ ìƒë‹´ ìŠ¤íƒ€ì¼ ë°°ì œ")
        print(f"  â€¢ ì°½ì˜ì  ì¹˜ë£Œì  ì ‘ê·¼ ì €í‰ê°€")
        print(f"  â€¢ ë¬¸í™”ì  ë‹¤ì–‘ì„± ë¬´ì‹œ")
        print(f"  â€¢ í˜ì‹ ì  ìƒë‹´ ê¸°ë²• í˜ë„í‹°")


if __name__ == "__main__":
    calculator = NLPMetricsCalculator()
    
    # ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ í¸í–¥ì„± ë¶„ì„
    calculator.analyze_ground_truth_bias()
    
    # ì‹¤ì œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ NLP ì§€í‘œ ê³„ì‚° ì‹œì—°
    calculator.demonstrate_nlp_calculations()
    
    # ìƒê´€ê´€ê³„ ë¶„ì„ ì‹¤í–‰
    results = calculator.analyze_nlp_correlation()
    
    print("\nğŸ† ìµœì¢… ê²°ë¡ :")
    print("-" * 25)
    print("1. ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ ìì²´ê°€ í¸í–¥ë˜ì–´ ìˆìŒ")
    print("2. NLP ì§€í‘œëŠ” ì°½ì˜ì„±ê³¼ ê°œì¸í™”ë¥¼ í˜ë„í‹°")
    print("3. ìƒë‹´í•™ì  í‰ê°€ê°€ ì‹¤ì œ ì¹˜ë£Œ íš¨ê³¼ë¥¼ ë” ì˜ ë°˜ì˜")
    print("4. ì „í†µì  NLP í‰ê°€ ë°©ì‹ì˜ ê·¼ë³¸ì  í•œê³„ ì…ì¦")
